{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02d592ba-ebe3-4293-999b-2ace3f26368f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tetra.model import eval\n",
    "from tetra.model import inference\n",
    "from tetra.data import data_loader\n",
    "from tetra.utils import file_io\n",
    "from pathlib import Path\n",
    "import importlib\n",
    "import shutil\n",
    "import os\n",
    "from pycocotools.coco import COCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80950a78-cbe6-4964-b976-18ee75e7d4d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'tetra.utils.file_io' from '/Users/mateobigearddasen/Documents/agrosup_stage/Tetra_Project/src/tetra/utils/file_io.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(file_io)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1c1a058-51d7-43cb-9d30-31bac10a62e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = os.path.abspath(\"../../runs/train/lyrurus_yolov11l_new_dataset/weights/best.pt\")\n",
    "dataset = Path(\"../../dataset/og/images\")\n",
    "inference_dataset = os.path.abspath(\"../../dataset/inference/images\")\n",
    "gt_annotations = \"../../dataset/og/_annotations.coco.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fe903eb-4bfa-48a7-9ed3-f386f17332f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select images of the dataset\n",
    "img_samples = data_loader.random_data_sample(dataset, 0.025, [\".jpg\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a854ec3-037a-4fba-bda0-9468b1e52a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change images directory\n",
    "for img in img_samples:\n",
    "    img = Path(img)\n",
    "    image = dataset / img\n",
    "    shutil.move(image, Path(inference_dataset) / img.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbbd60a6-defe-4083-b763-2f31ea54f9b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.02s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "#Get ground truth annotations\n",
    "coco_gt = COCO(gt_annotations)\n",
    "#Map id to image name\n",
    "file_to_id = {img[\"file_name\"]: img[\"id\"] for img in coco_gt.dataset[\"images\"] if img[\"file_name\"] in img_samples}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f768eea-5be0-4638-9767-a9a8194112d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing prediction on 63 slices.\n"
     ]
    }
   ],
   "source": [
    "#Inference of the data \n",
    "predictions = []\n",
    "for f in Path(inference_dataset).iterdir():\n",
    "    if f.suffix.lower() == \".jpg\":\n",
    "        prediction = inference.solo_inference(model, inference_dataset + f\"/{f.name}\")\n",
    "        prediction = prediction.to_coco_annotations()\n",
    "        for ann in prediction:\n",
    "            #Convert id to the gt id\n",
    "            ann[\"image_id\"] = file_to_id[f.name]\n",
    "            ann[\"category_id\"] = 1\n",
    "            #Change category name\n",
    "            ann[\"category_name\"] = \"Lyrurus_tetrix\"\n",
    "        predictions.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46eb89b6-d82d-4dc4-ad97-e01800af2ae5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metric_val = eval.eval_hr_images(\"../../dataset/og/_annotations.coco.json\", \"./annotations/yolov11l_new_dataset.coco.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cc2939-822a-4e05-b4e7-7a8bd7f6e302",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter predictions\n",
    "filtered_predictions = [ann for ann in file_io.flatten_pred(predictions) if ann[\"score\"] > 0.386]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d46248-22ec-4f4d-a209-e8614382fa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save predictions\n",
    "file_io.save_coco_labels(filtered_predictions, \"./annotations\", \"yolov11l_new_dataset.coco.json\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecdcf2f-8b48-4b78-bac8-455a87fb2263",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_val.evaluate()\n",
    "metric_val.accumulate()\n",
    "metric_val.summarize()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
